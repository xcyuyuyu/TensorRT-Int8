# TensorRT-Int8
TensorRT Int8 quantization demo
# TensorRT Int8 Quantization Demo

1. Convert PyTorch Model to ONNX model
```
python to_onnx.py
```
2. Run the TensorRT demo
```
python trt_demo.py
```
3. Run the TensorRT Int8 Quantization demo
```
python trt_demo_int8.py
```
